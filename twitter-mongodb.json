{"paragraphs":[{"text":"%pyspark\n\nimport os\nimport io\nimport json\nimport pymongo\nfrom pprint import pprint as pp\nimport csv\nfrom collections import namedtuple\nimport time\n\ndef parse_date(s):\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(s,'%a %b %d %H:%M:%S +0000 %Y'))\n    \ndef parse_geo(g,index):\n    try:\n        return str(g[\"geo\"][\"coordinates\"][index])\n    except:\n        return \"\"\n        \ndef extract_tweet(statuses):\n    return [ {'id'         :status['id'], \n              'created_at' :parse_date(status['created_at']), \n              'user_id'    :status['user']['id'],\n              'user_name'  :status['user']['name'], \n              'tweet_text' :status['text'].encode('utf-8'), \n              'url'        :url['expanded_url']} \n                               for status in statuses\n                                   for url in status['entities']['urls'] ]\n                                   \ndef extract_tweet_noURL(statuses):\n    return [ {'id'         :status['id'], \n              'created_at' :parse_date(status['created_at']), \n              'user_id'    :status['user']['id'],\n              'user_name'  :status['user']['name'], \n              'tweet_text' :status['text'].encode('utf-8') }\n                               for status in statuses ]\n                               \n\nfields01 = ['id', 'created_at', 'user_id', 'user_name', 'tweet_text', 'url']\nTweet01 = namedtuple('Tweet01',fields01)\n\n\ndef parse_tweet(data):\n    \"\"\"\n    Parse a ``tweet`` from the given response data.\n    \"\"\"\n    return Tweet01(\n        id=data.get('id', None),\n        created_at=data.get('created_at', None),\n        user_id=data.get('user_id', None),\n        user_name=data.get('user_name', None),\n        tweet_text=data.get('tweet_text', None),\n        url=data.get('url')\n    )\n\n\nfields00 = ['id', 'created_at', 'user_id', 'user_name', 'tweet_text']\nTweet00 = namedtuple('Tweet00',fields00)\n\n\ndef parse_tweet_noURL(data):\n    \"\"\"\n    Parse a ``tweet`` from the given response data.\n    \"\"\"\n    return Tweet00(\n        id=data.get('id', None),\n        created_at=data.get('created_at', None),\n        user_id=data.get('user_id', None),\n        user_name=data.get('user_name', None),\n        tweet_text=data.get('tweet_text', None)\n    )\n    \nimport twitter\nimport urlparse # python 2.7\n# import urllib # python 3.0\nimport logging\nimport time\nfrom datetime import datetime\n\n","dateUpdated":"2016-12-22T16:28:26+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1482423851081_-743521598","id":"20161222-162411_138817375","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-12-22T16:24:11+0000","dateStarted":"2016-12-22T16:28:26+0000","dateFinished":"2016-12-22T16:28:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1692"},{"text":"%pyspark\n\nfrom pymongo import MongoClient as MCli\n\nclass IO_mongo(object):    \n    conn={'host':'ec2-54-67-18-190.us-west-1.compute.amazonaws.com', 'ip':'27017'}\n    \n    \n    def __init__(self, db='twtr_db', coll='twtr_coll', **conn ):        \n        # Connects to the MongoDB server         \n        self.client = MCli(**conn)        \n        self.db = self.client[db]        \n        self.coll = self.db[coll]\n        \n    def save(self, data):        \n        # Insert to collection in db          \n        return self.coll.insert(data)\n\n    def load(self, return_cursor=False, criteria=None, projection=None):            \n        if criteria is None:                \n            criteria = {}            \n        if projection is None:                \n            cursor = self.coll.find(criteria)            \n        else:                \n            cursor = self.coll.find(criteria, projection)            \n        \n        # Return a cursor for large amounts of data            \n        if return_cursor:                \n            return cursor            \n        else:                \n            return [ item for item in cursor ]","dateUpdated":"2016-12-22T17:07:46+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1482423882744_1876111070","id":"20161222-162442_306053399","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-12-22T16:24:42+0000","dateStarted":"2016-12-22T17:07:46+0000","dateFinished":"2016-12-22T17:07:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1693","focus":true},{"text":"%pyspark\n\nclass TwitterAPI(object):\n    \"\"\"\n    TwitterAPI class allows the Connection to Twitter via OAuth\n    once you have registered with Twitter and receive the \n    necessary credentials \n    \"\"\"\n\n    def __init__(self): \n        consumer_key = 'J0z9I39drXzQVfdIFKof38oos'\n        consumer_secret = 'fKlNgF4hZ8tacNnzuKslgU2781CSa79IRIYzgiVQVUCFSSGrkp'\n        access_token = '87976598-PaVQ8QBJxwrO7mlcUR533ybkKgltqzrA4wX6U3RY6'\n        access_secret = 'pQhMpiQwYKgmDCnyD0FO1Dhl7sEJ8Ifq0RbSeuvdrxhhi'\n        self.consumer_key = consumer_key\n        self.consumer_secret = consumer_secret\n        self.access_token = access_token\n        self.access_secret = access_secret\n        self.retries = 3\n        self.auth = twitter.oauth.OAuth(access_token, access_secret, consumer_key, consumer_secret)\n        self.api = twitter.Twitter(auth=self.auth)\n        \n        # logger initialisation\n        appName = 'twt150530'\n        self.logger = logging.getLogger(appName)\n        #self.logger.setLevel(logging.DEBUG)\n        # create console handler and set level to debug\n        logPath = ''\n        fileName = appName\n        # fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(logPath, fileName))\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n        # fileHandler.setFormatter(formatter)\n        # self.logger.addHandler(fileHandler) \n        self.logger.setLevel(logging.DEBUG)\n        \n        # Save to JSON file initialisation\n        # jsonFpath = ''\n        # jsonFname = 'twtr15053001'\n        # self.jsonSaver = IO_json(jsonFpath, jsonFname)\n        \n        # Save to MongoDB Intitialisation\n        self.mongoSaver = IO_mongo(db='twtr01_db', coll='twtr01_coll')\n\n\n    def searchTwitter(self, q, max_res=10,**kwargs):\n        search_results = self.api.search.tweets(q=q, count=10, **kwargs)\n        statuses = search_results['statuses']\n        max_results = min(1000, max_res)\n        \n        for _ in range(10):\n            try:\n                next_results = search_results['search_metadata']['next_results']\n                # self.logger.info('info in searchTwitter - next_results:%s'% next_results[1:])\n            except KeyError as e:\n                self.logger.error('error in searchTwitter: %s', e)\n                break\n            \n            next_results = urlparse.parse_qsl(next_results[1:]) # python 2.7\n            # next_results = urllib.parse.parse_qsl(next_results[1:])\n            # self.logger.info('info in searchTwitter - next_results[max_id]:', next_results[0:])\n            kwargs = dict(next_results)\n            # self.logger.info('info in searchTwitter - next_results[max_id]:%s'% kwargs['max_id'])\n            search_results = self.api.search.tweets(**kwargs)\n            statuses += search_results['statuses']\n            self.saveTweets(search_results['statuses'])\n            \n            if len(statuses) > max_results:\n                self.logger.info('info in searchTwitter - got %i tweets - max: %i' %(len(statuses), max_results))\n                break\n        return statuses\n\n    def saveTweets(self, statuses):\n        # Saving to JSON File\n        # self.jsonSaver.save(statuses)\n        \n        # Saving to MongoDB\n        for s in statuses:\n            self.mongoSaver.save(s)\n\n    def parseTweets(self, statuses):\n        return [ (status['id'], \n                  status['created_at'], \n                  status['user']['id'],\n                  status['user']['name'], \n                  status['text'], \n                  url['expanded_url']) \n                        for status in statuses \n                            for url in status['entities']['urls'] ]\n\n\n    def getTweets(self, q,  max_res=10):\n        \"\"\"\n        Make a Twitter API call whilst managing rate limit and errors.\n        \"\"\"\n        def handleError(e, wait_period=2, sleep_when_rate_limited=True):\n\n            if wait_period > 3600: # Seconds\n                self.logger.error('Too many retries in getTweets: %s', e)\n                raise e\n            if e.e.code == 401:\n                self.logger.error('error 401 * Not Authorised * in getTweets: %s', e)\n                return None\n            elif e.e.code == 404:\n                self.logger.error('error 404 * Not Found * in getTweets: %s', e)\n                return None\n            elif e.e.code == 429: \n                self.logger.error('error 429 * API Rate Limit Exceeded * in getTweets: %s', e)\n                if sleep_when_rate_limited:\n                    self.logger.error('error 429 * Retrying in 15 minutes * in getTweets: %s', e)\n                    sys.stderr.flush()\n                    time.sleep(60*15 + 5)\n                    self.logger.info('error 429 * Retrying now * in getTweets: %s', e)\n                    return 2\n                else:\n                    raise e # Caller must handle the rate limiting issue\n            elif e.e.code in (500, 502, 503, 504):\n                self.logger.info('Encountered %i Error. Retrying in %i seconds' % (e.e.code, wait_period))\n                time.sleep(wait_period)\n                wait_period *= 1.5\n                return wait_period\n            else:\n                self.logger.error('Exit - aborting - %s', e)\n                raise e\n        \n        while True:\n            try:\n                self.searchTwitter( q, max_res=10)\n            except twitter.api.TwitterHTTPError as e:\n                error_count = 0 \n                wait_period = handleError(e, wait_period)\n                if wait_period is None:\n                    return","dateUpdated":"2016-12-22T17:07:50+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1482424142113_-818317771","id":"20161222-162902_510315720","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-12-22T16:29:02+0000","dateStarted":"2016-12-22T17:07:50+0000","dateFinished":"2016-12-22T17:07:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1694","focus":true},{"text":"%pyspark\n\nt= TwitterAPI()\nq=\"gladwell\"\ntsearch = t.searchTwitter(q)","dateUpdated":"2016-12-22T17:07:55+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1482424294116_1662005147","id":"20161222-163134_1142119945","result":{"code":"ERROR","type":"TEXT","msg":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3141072948686522940.py\", line 267, in <module>\n    raise Exception(traceback.format_exc())\nException: Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-3141072948686522940.py\", line 265, in <module>\n    exec(code)\n  File \"<stdin>\", line 3, in <module>\n  File \"<stdin>\", line 40, in searchTwitter\n  File \"<stdin>\", line 47, in saveTweets\n  File \"<stdin>\", line 9, in save\n  File \"/usr/local/lib64/python2.7/site-packages/pymongo/collection.py\", line 2467, in insert\n    with self._socket_for_writes() as sock_info:\n  File \"/usr/lib64/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib64/python2.7/site-packages/pymongo/mongo_client.py\", line 823, in _get_socket\n    server = self._get_topology().select_server(selector)\n  File \"/usr/local/lib64/python2.7/site-packages/pymongo/topology.py\", line 214, in select_server\n    address))\n  File \"/usr/local/lib64/python2.7/site-packages/pymongo/topology.py\", line 189, in select_servers\n    self._error_message(selector))\nServerSelectionTimeoutError: localhost:27017: [Errno 111] Connection refused\n\n"},"dateCreated":"2016-12-22T16:31:34+0000","dateStarted":"2016-12-22T17:07:55+0000","dateFinished":"2016-12-22T17:08:25+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:1695","focus":true},{"text":"","dateUpdated":"2016-12-22T16:32:43+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1482424352752_397366684","id":"20161222-163232_100297865","dateCreated":"2016-12-22T16:32:32+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:1696"}],"name":"twitter-mongodb","id":"2C5YC2BQ5","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}